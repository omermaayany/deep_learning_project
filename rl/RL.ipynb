{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6109,"status":"ok","timestamp":1761125601259,"user":{"displayName":"David Roskin","userId":"03626795361254247188"},"user_tz":-180},"id":"kNHMdLVWQp3_","outputId":"5cf93c99-e520-4805-c36e-9d04bb92af4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","import os, re, random, copy\n","from typing import List, Tuple, Dict, Optional, Iterable, Set\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hex-JlgJRIIb","executionInfo":{"status":"ok","timestamp":1761125601267,"user_tz":-180,"elapsed":4,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["PATH        = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_project/RL/EPIC_100_train.csv\"\n","CKPT_PATH   = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_project/RL/bias_rl_latest.pt\"\n","START_TOKEN = \"start_of_video\"\n","END_TOKEN   = \"end_of_video\"\n","PAD_TOKEN   = \"pad\"\n","IRRELEVANT_OBJS = {\n","    \"knife\",\"spoon\",\"fork\",\"pan\",\"pot\",\"cup\",\"plate\",\"bowl\",\"sink\",\"tap\",\"fridge\",\n","    \"microwave\",\"hob\",\"stove\",\"drawer\",\"cupboard\",\"sponge\",\"towel\",\"board\",\"cutting board\",\n","    \"counter\",\"bin\",\"trash\",\"packaging\",\"wrapper\",\"bottle\",\"lid\",\"jar\",\"foil\",\"film\",\"door\",\n","    \"light\",\"container\"\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vXSyJ1mEVWeU","executionInfo":{"status":"ok","timestamp":1761125601290,"user_tz":-180,"elapsed":7,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["def dev(device: Optional[str] = None) -> torch.device:\n","    return torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","\n","def clean_data(s: Optional[str]) -> str:\n","    if pd.isna(s):\n","        return \"\"\n","    s = (s or \"\").lower().strip()\n","    s = re.sub(r\"[^a-z0-9\\s\\-]\", \"\", s)\n","    return s\n","\n","def remove_same_con_act(seq: List[str]) -> List[str]:\n","    if len(seq) <= 1: return seq\n","    out = [seq[0]]\n","    for a in seq[1:]:\n","        if a != out[-1]: out.append(a)\n","    return out\n","\n","def build_unbiased_union_mask(allowed: Iterable[int], V: int, device: Optional[str] = None) -> torch.Tensor:\n","    d = dev(device)\n","    mask = torch.full((1, V), -1e9, dtype=torch.float32, device=d)\n","    allowed = list(set(int(a) for a in allowed))\n","    if allowed:\n","        idx = torch.tensor(sorted(allowed), dtype=torch.long, device=d)\n","        mask[0, idx] = 0.0\n","    return mask\n","\n","def compute_gae(rewards: List[float], terms: List[bool], values: List[float],\n","                gamma: float = 0.99, lamd: float = 1.0, last_value: float = 0.0):\n","    T = len(rewards)\n","    adv = [0.0] * T\n","    vals = list(map(float, values)) + [float(last_value)]\n","    gae = 0.0\n","    for t in range(T-1, -1, -1):\n","        delta = rewards[t] + (0.0 if terms[t] else gamma * vals[t+1]) - vals[t]\n","        gae = delta + (0.0 if terms[t] else gamma * lamd) * gae\n","        adv[t] = gae\n","    ret = [adv[t] + vals[t] for t in range(T)]\n","    return adv, ret\n","\n","def _rolling_mean(xs: List[float], wnd: int) -> float:\n","    if not xs:\n","        return float(\"nan\")\n","    arr = np.array(xs[-min(wnd, len(xs)):], dtype=np.float64)\n","    return float(np.nanmean(arr)) if arr.size else float(\"nan\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VqoWg3TDNmca","executionInfo":{"status":"ok","timestamp":1761125601306,"user_tz":-180,"elapsed":14,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["class _Node:\n","    def __init__(self):\n","        self.term: bool = False\n","        self.children: Dict[int, \"_Node\"] = {}\n","\n","def _tree_step(cur: Optional[_Node], action: int):\n","    if cur is None or action not in cur.children:\n","        return None, False, True\n","    nxt = cur.children[action]\n","    return nxt, True, nxt.term\n","\n","def _advance_to_node(seq: List[int], root: _Node):\n","    node = root\n","    if node is None: return None, False, True\n","    if not seq: return node, True, node.term\n","    for i,a in enumerate(seq):\n","        node, valid, term = _tree_step(node, a)\n","        if not valid: return node, False, True\n","        if term and i < len(seq)-1: return node, False, True\n","    return node, True, node.term"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MO8ItYUPYhk8","executionInfo":{"status":"ok","timestamp":1761125601323,"user_tz":-180,"elapsed":14,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["class EmbeddedDatabase:\n","    def __init__(self, df: pd.DataFrame, min_len: int = 2, remove_irr: bool = True, remove_con: bool = True):\n","        self.df = df.copy()\n","        self.min_len = min_len\n","        self.remove_irr = remove_irr\n","        self.remove_con = remove_con\n","        self.df = self._clean_df()\n","        self.action_seq_df = self._to_action_seqs()\n","        self.embed_to_act, self.act_to_embed = self._make_vocab()\n","        self.embedded_df = self._to_embedded_df()\n","        self.tree = self._build_tree(self.embedded_df[\"embedded_seq\"].tolist())\n","        self.pad_id   = self.act_to_embed[PAD_TOKEN]\n","        self.start_id = self.act_to_embed[START_TOKEN]\n","        self.end_id   = self.act_to_embed[END_TOKEN]\n","        self.V        = len(self.embed_to_act)\n","\n","    def _clean_df(self):\n","        keep = [\"video_id\", \"verb\", \"noun\", \"narration\"]\n","        df = self.df.loc[:, keep].copy()\n","        df[\"verb\"] = df[\"verb\"].apply(clean_data)\n","        df[\"noun\"] = df[\"noun\"].apply(clean_data)\n","        if self.remove_irr:\n","            df = df.loc[~df[\"noun\"].isin(IRRELEVANT_OBJS)].copy()\n","        df[\"action\"] = (df[\"verb\"] + \" \" + df[\"noun\"]).str.strip()\n","        return df\n","\n","    def _to_action_seqs(self):\n","        g = self.df.groupby(\"video_id\", sort=False)[\"action\"].agg(list).reset_index(name=\"actions_seq\")\n","        if self.remove_con:\n","            g[\"actions_seq\"] = g[\"actions_seq\"].apply(remove_same_con_act)\n","        g = g.loc[g[\"actions_seq\"].apply(len) >= self.min_len]\n","        g[\"actions_seq\"] = g[\"actions_seq\"].apply(lambda xs: [START_TOKEN] + xs + [END_TOKEN])\n","        return g\n","\n","    def _make_vocab(self):\n","        special = [PAD_TOKEN, END_TOKEN, START_TOKEN]\n","        pool = set()\n","        for seq in self.action_seq_df[\"actions_seq\"]:\n","            for a in seq:\n","                if a not in special:\n","                    pool.add(a)\n","        pool = sorted(pool)\n","        act_to_embed, embed_to_act = {}, {}\n","        for i,a in enumerate(special):\n","            act_to_embed[a] = i; embed_to_act[i] = a\n","        off = len(special)\n","        for i,a in enumerate(pool):\n","            act_to_embed[a] = i + off\n","            embed_to_act[i + off] = a\n","        return embed_to_act, act_to_embed\n","\n","    def embed_seq(self, seq: List[str]) -> List[int]:\n","        return [self.act_to_embed[a] for a in seq]\n","\n","    def _to_embedded_df(self):\n","        df = self.action_seq_df.copy()\n","        df[\"embedded_seq\"] = df[\"actions_seq\"].apply(self.embed_seq)\n","        return df\n","\n","    def _build_tree(self, seqs: List[List[int]]) -> _Node:\n","        root = _Node()\n","        for seq in seqs:\n","            cur = root\n","            for a in seq:\n","                if a not in cur.children:\n","                    cur.children[a] = _Node()\n","                cur = cur.children[a]\n","            cur.term = True\n","        return root\n","Embedded_database = EmbeddedDatabase\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"BtWiI1FtZQHc","executionInfo":{"status":"ok","timestamp":1761125601360,"user_tz":-180,"elapsed":33,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["class SeqActMap:\n","    def __init__(self, embedded: EmbeddedDatabase, min_len=1, max_len=50, min_seq_len=1):\n","        self.embedded = embedded\n","        self.min_len = min_len\n","        self.max_len = max_len\n","        self.min_seq_len = min_seq_len\n","        self.act_seq_map: Dict[Tuple[int,...], Set[int]] = {}\n","        for seq in embedded.embedded_df[\"embedded_seq\"]:\n","            for i in range(1, len(seq)):\n","                nxt = seq[i]\n","                for j in range(0, i):\n","                    L = i - j\n","                    if L < self.min_len or L > self.max_len:\n","                        continue\n","                    sub = tuple(seq[j:i])\n","                    self.act_seq_map.setdefault(sub, set()).add(nxt)\n","        self.all_sub_seq = [k for k in self.act_seq_map.keys() if len(k) >= self.min_seq_len]\n","\n","    def get_next_legal_acts(self, seq: List[int]) -> Set[int]:\n","        if not seq:\n","            return set()\n","        key = tuple(seq[-self.max_len:])\n","        return self.act_seq_map.get(key, set())\n","\n","def union_legals_from_map(mapper: SeqActMap, seq_ids: List[int], max_backoff: Optional[int] = None) -> Set[int]:\n","    if not seq_ids: return set()\n","    L = len(seq_ids)\n","    start_i = max(0, L - (max_backoff or L))\n","    out: Set[int] = set()\n","    for i in range(start_i, L):\n","        legal = mapper.get_next_legal_acts(seq_ids[i:])\n","        if legal: out.update(legal)\n","    return out\n","\n","Seq_act_map = SeqActMap"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BIeEu-Sroc-9","executionInfo":{"status":"ok","timestamp":1761125601365,"user_tz":-180,"elapsed":2,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["class SequencePolicy(nn.Module):\n","    def __init__(self, action_size: int, d_model: int = 128, hidden: int = 256, pad_id: int = 0):\n","        super().__init__()\n","        self.embed  = nn.Embedding(action_size, d_model, padding_idx=pad_id)\n","        self.gru    = nn.GRU(d_model, hidden, batch_first=True)\n","        self.policy = nn.Linear(hidden, action_size)\n","        self.value  = nn.Linear(hidden, 1)\n","\n","    def forward(self, seq: torch.Tensor, lengths: torch.Tensor, mask: Optional[torch.Tensor] = None):\n","        length_s, idx = lengths.sort(descending=True)\n","        seq_s = seq.index_select(0, idx)\n","        emb = self.embed(seq_s)\n","        packed = torch.nn.utils.rnn.pack_padded_sequence(emb, length_s.cpu(), batch_first=True, enforce_sorted=True)\n","        _, h_n = self.gru(packed)\n","        h = h_n[-1]\n","        _, inv = idx.sort()\n","        h = h.index_select(0, inv)\n","        logits = self.policy(h)\n","        if mask is not None:\n","            logits = logits + mask.to(logits.dtype).to(logits.device)\n","            logits = torch.nan_to_num(logits, nan=-1e9, neginf=-1e9)\n","        val = self.value(h)\n","        return logits, val"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ojsZRlrtsOBs","executionInfo":{"status":"ok","timestamp":1761125601369,"user_tz":-180,"elapsed":2,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["def build_prefix_pool_and_index(embedder: EmbeddedDatabase):\n","    gt_pool: List[Tuple[List[int], int]] = []\n","    prefix2idx: Dict[Tuple[int,...], int] = {}\n","    prefix_list: List[Tuple[int,...]] = []\n","    for seq in embedder.embedded_df[\"embedded_seq\"].tolist():\n","        for i in range(1, len(seq)):\n","            gt_pool.append((seq, i))\n","            p = tuple(seq[:i])\n","            if p not in prefix2idx:\n","                prefix2idx[p] = len(prefix_list)\n","                prefix_list.append(p)\n","    return gt_pool, prefix2idx, prefix_list"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"iX0SCD5_TAqC","executionInfo":{"status":"ok","timestamp":1761125601376,"user_tz":-180,"elapsed":3,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["class PrefixBiasTable:\n","    def __init__(self, V: int, prefix2idx: Dict[Tuple[int,...], int], prefix_list: List[Tuple[int,...]],\n","                 rows: Optional[Dict[int, np.ndarray]] = None, device: Optional[str] = None):\n","        self.V = int(V)\n","        self.prefix2idx = dict(prefix2idx)\n","        self.prefix_list = list(prefix_list)\n","        self.rows: Dict[int, np.ndarray] = rows if rows is not None else {}\n","        self.device = device\n","\n","    def row_tensor(self, prefix_tuple: Iterable[int], mask_float: Optional[torch.Tensor] = None,\n","                   device: Optional[str] = None) -> torch.Tensor:\n","        d = dev(device or self.device)\n","        pidx = self.prefix2idx.get(tuple(prefix_tuple), None)\n","        if pidx is None:\n","            out = torch.zeros(1, self.V, dtype=torch.float32, device=d)\n","        else:\n","            arr = self.rows.get(pidx, None)\n","            out = torch.from_numpy(arr).to(d, torch.float32).unsqueeze(0) if arr is not None \\\n","                else torch.zeros(1, self.V, dtype=torch.float32, device=d)\n","        if mask_float is not None:\n","            out = out.masked_fill(mask_float < 0, 0.0)\n","        return out\n","\n","    def update(self, prefix_tuple: Iterable[int], action: int, delta: float, clip: float = 2.0) -> None:\n","        pidx = self.prefix2idx.get(tuple(prefix_tuple), None)\n","        if pidx is None: return\n","        row = self.rows.get(pidx)\n","        if row is None:\n","            row = np.zeros(self.V, dtype=np.float32)\n","            self.rows[pidx] = row\n","        row[action] = float(np.clip(row[action] + float(delta), -float(clip), float(clip)))\n","\n","    def state_dict(self) -> Dict[str, object]:\n","        return {\n","            \"V\": self.V,\n","            \"rows\": self.rows,\n","            \"prefix_list\": self.prefix_list,\n","            \"prefix2idx\": self.prefix2idx,\n","        }\n","\n","    @staticmethod\n","    def from_state(state: Dict[str, object], device: Optional[str] = None) -> \"PrefixBiasTable\":\n","        return PrefixBiasTable(\n","            V=int(state[\"V\"]),\n","            prefix2idx=dict(state[\"prefix2idx\"]),\n","            prefix_list=list(state[\"prefix_list\"]),\n","            rows=dict(state[\"rows\"]),\n","            device=device,\n","        )\n"]},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate_with_bias(embedder: EmbeddedDatabase, mapper: SeqActMap, model: SequencePolicy, bias: PrefixBiasTable,\n","                       *, max_backoff: Optional[int] = None, show_progress: bool = True,\n","                       device: Optional[str] = None) -> Tuple[float,float]:\n","    d = dev(device)\n","    was_training = model.training\n","    model.eval()\n","    try:\n","        from tqdm.auto import tqdm\n","        wrap = (lambda it: tqdm(it, desc=\"[Eval/Biased]\", leave=False)) if show_progress else (lambda it: it)\n","    except Exception:\n","        wrap = (lambda it: it)\n","    V = embedder.V\n","    samples: List[Tuple[List[int], int]] = []\n","    for seq in embedder.embedded_df[\"embedded_seq\"].tolist():\n","        for i in range(1, len(seq)):\n","            samples.append((seq[:i], seq[i]))\n","    total = multi_total = correct = multi_correct = single = 0\n","    for prefix, target in wrap(samples):\n","        allowed = union_legals_from_map(mapper, prefix, max_backoff=max_backoff)\n","        if not allowed:\n","            continue\n","        mask = build_unbiased_union_mask(allowed, V, d.type)\n","        s_t = torch.tensor([prefix], dtype=torch.long, device=d)\n","        L_t = torch.tensor([len(prefix)], dtype=torch.long, device=d)\n","        logits, _ = model(s_t, L_t, mask)\n","        b_row = bias.row_tensor(prefix, mask_float=mask, device=d)\n","        logits = logits + b_row\n","        pred = int(torch.argmax(logits, dim=-1).item())\n","\n","        total += 1\n","        if pred == target: correct += 1\n","        if len(allowed) == 1:\n","            single += 1\n","        else:\n","            multi_total += 1\n","            if pred == target: multi_correct += 1\n","    acc = (correct / total) if total else 0.0\n","    macc = (multi_correct / multi_total) if multi_total else 0.0\n","    print(f\"[Eval/Biased] prefixes={total}  acc={acc:.4f}  multi_acc={macc:.4f}  single_frac={single/max(1,total):.3f}\")\n","    if was_training: model.train()\n","    return acc, macc"],"metadata":{"id":"4Gu07Em7DifJ","executionInfo":{"status":"ok","timestamp":1761125601380,"user_tz":-180,"elapsed":2,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BTioE_t74VPy","executionInfo":{"status":"ok","timestamp":1761125601384,"user_tz":-180,"elapsed":2,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["def _atomic_torch_save(obj, path):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    tmp = path + \".tmp\"\n","    torch.save(obj, tmp)\n","    os.replace(tmp, path)\n","\n","def _embedder_signature(embedder: EmbeddedDatabase):\n","    return {\n","        \"V\": embedder.V,\n","        \"act_to_embed\": dict(embedder.act_to_embed),\n","        \"embed_to_act\": dict(embedder.embed_to_act),\n","    }\n","def _check_embedder_compat(embedder: EmbeddedDatabase, sig, strict=True):\n","    ok = (\n","        sig.get(\"V\") == embedder.V and\n","        sig.get(\"act_to_embed\") == embedder.act_to_embed and\n","        sig.get(\"embed_to_act\") == embedder.embed_to_act\n","    )\n","    if strict and not ok:\n","        raise ValueError(\"Checkpoint action mapping does not match current embedder.\")\n","    return ok\n","\n","def _rng_pack():\n","    return {\n","        \"py\": random.getstate(),\n","        \"np\": np.random.get_state(),\n","        \"torch_cpu\": torch.get_rng_state().tolist(),\n","        \"torch_cuda\": [t.tolist() for t in torch.cuda.get_rng_state_all()] if torch.cuda.is_available() else None,\n","    }\n","\n","def _rng_unpak(rng):\n","    try:\n","        random.setstate(rng[\"py\"])\n","        np.random.set_state(tuple(rng[\"np\"]))\n","        torch.set_rng_state(torch.tensor(rng[\"torch_cpu\"], dtype=torch.uint8))\n","        if torch.cuda.is_available() and rng[\"torch_cuda\"] is not None:\n","            states = [torch.tensor(x, dtype=torch.uint8) for x in rng[\"torch_cuda\"]]\n","            torch.cuda.set_rng_state_all(states)\n","    except Exception:\n","        pass\n","\n","def _reindex_bias_rows_to_prefix_map(bias_state, new_prefix2idx):\n","    old_rows = bias_state[\"rows\"]\n","    old_list = bias_state[\"prefix_list\"]\n","    new_rows = {}\n","    for old_idx, row in old_rows.items():\n","        if 0 <= old_idx < len(old_list):\n","            pref = tuple(old_list[old_idx])\n","            new_idx = new_prefix2idx.get(pref, None)\n","            if new_idx is not None:\n","                new_rows[new_idx] = row.copy()\n","    inv = [None] * len(new_prefix2idx)\n","    for p, idx in new_prefix2idx.items():\n","        inv[idx] = tuple(p)\n","    bias_state[\"rows\"] = new_rows\n","    bias_state[\"prefix_list\"] = inv\n","    bias_state[\"prefix2idx\"] = dict(new_prefix2idx)\n","    return bias_state\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"A0BpP82q_F9J","executionInfo":{"status":"ok","timestamp":1761125601414,"user_tz":-180,"elapsed":28,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["def _init_history(history=None):\n","    if history is None:\n","        history = {}\n","    history.setdefault(\"train\", {\n","        \"ep\": [],\n","        \"return\": [],\n","        \"steps\": [],\n","        \"corr_frac\": [],\n","        \"pol_loss\": [],\n","        \"val_loss\": [],\n","        \"entropy\": [],\n","        \"smooth_return\": []\n","    })\n","    history.setdefault(\"eval\", {\n","        \"ep\": [],\n","        \"acc\": [],\n","        \"multi_acc\": []\n","    })\n","    return history\n","\n","def _history_to_dfs(history):\n","    h = _init_history(history)\n","    train_df = pd.DataFrame(h[\"train\"])\n","    eval_df  = pd.DataFrame(h[\"eval\"])\n","    return train_df, eval_df\n","\n","def _save_history_artifacts(history, out_dir, tag=\"latest\"):\n","    os.makedirs(out_dir, exist_ok=True)\n","    train_df, eval_df = _history_to_dfs(history)\n","    train_csv = os.path.join(out_dir, f\"train_history_{tag}.csv\")\n","    eval_csv  = os.path.join(out_dir, f\"eval_history_{tag}.csv\")\n","    train_df.to_csv(train_csv, index=False)\n","    eval_df.to_csv(eval_csv, index=False)\n","    npz_path = os.path.join(out_dir, f\"metrics_{tag}.npz\")\n","    np.savez_compressed(\n","        npz_path,\n","        train_ep=np.array(history[\"train\"][\"ep\"]),\n","        train_return=np.array(history[\"train\"][\"return\"]),\n","        train_steps=np.array(history[\"train\"][\"steps\"]),\n","        train_corr_frac=np.array(history[\"train\"][\"corr_frac\"]),\n","        train_pol_loss=np.array(history[\"train\"][\"pol_loss\"]),\n","        train_val_loss=np.array(history[\"train\"][\"val_loss\"]),\n","        train_entropy=np.array(history[\"train\"][\"entropy\"]),\n","        train_smooth_return=np.array(history[\"train\"][\"smooth_return\"]),\n","        eval_ep=np.array(history[\"eval\"][\"ep\"]),\n","        eval_acc=np.array(history[\"eval\"][\"acc\"]),\n","        eval_multi_acc=np.array(history[\"eval\"][\"multi_acc\"]),\n","    )\n","    if len(history[\"train\"][\"ep\"]) > 1:\n","        fig = plt.figure(figsize=(8,4.5))\n","        plt.plot(history[\"train\"][\"ep\"], history[\"train\"][\"return\"], label=\"return\")\n","        plt.plot(history[\"train\"][\"ep\"], history[\"train\"][\"smooth_return\"], label=\"smoothed\")\n","        plt.xlabel(\"episode\"); plt.ylabel(\"return\"); plt.title(\"Episode return\")\n","        plt.legend(); plt.tight_layout()\n","        fig.savefig(os.path.join(out_dir, f\"plot_return_{tag}.png\"))\n","        plt.close(fig)\n","        fig = plt.figure(figsize=(8,4.5))\n","        plt.plot(history[\"train\"][\"ep\"], np.array(history[\"train\"][\"corr_frac\"])*100.0)\n","        plt.xlabel(\"episode\"); plt.ylabel(\"correct %\"); plt.title(\"Episode correctness (%)\")\n","        plt.tight_layout()\n","        fig.savefig(os.path.join(out_dir, f\"plot_correctness_{tag}.png\"))\n","        plt.close(fig)\n","        fig = plt.figure(figsize=(8,4.5))\n","        plt.plot(history[\"train\"][\"ep\"], history[\"train\"][\"pol_loss\"], label=\"policy\")\n","        plt.plot(history[\"train\"][\"ep\"], history[\"train\"][\"val_loss\"], label=\"value\")\n","        plt.plot(history[\"train\"][\"ep\"], history[\"train\"][\"entropy\"], label=\"entropy\")\n","        plt.xlabel(\"episode\"); plt.ylabel(\"loss\"); plt.title(\"Loss components\")\n","        plt.legend(); plt.tight_layout()\n","        fig.savefig(os.path.join(out_dir, f\"plot_losses_{tag}.png\"))\n","        plt.close(fig)\n","    if len(history[\"eval\"][\"ep\"]) > 0:\n","        fig = plt.figure(figsize=(8,4.5))\n","        plt.plot(history[\"eval\"][\"ep\"], np.array(history[\"eval\"][\"acc\"])*100.0, label=\"acc\")\n","        plt.plot(history[\"eval\"][\"ep\"], np.array(history[\"eval\"][\"multi_acc\"])*100.0, label=\"multi-acc\")\n","        plt.xlabel(\"episode\"); plt.ylabel(\"accuracy %\"); plt.title(\"Evaluation\")\n","        plt.legend(); plt.tight_layout()\n","        fig.savefig(os.path.join(out_dir, f\"plot_eval_{tag}.png\"))\n","        plt.close(fig)\n","def save_bias_rl_checkpoint(ckpt_path, *, model, optimizer, bias, embedder, ep,\n","                            smoothed_return, best_metrics, history,\n","                            rng_pack=None, tag=\"latest\"):\n","    state = {\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n","        \"bias_state\": bias.state_dict(),\n","        \"episode\": int(ep),\n","        \"smoothed_return\": float(smoothed_return) if smoothed_return is not None else None,\n","        \"best_metrics\": dict(best_metrics or {}),\n","        \"history\": _init_history(history),\n","        \"embedder_sig\": _embedder_signature(embedder),\n","        \"rng\": rng_pack or _rng_pack(),\n","        \"tag\": tag,\n","    }\n","    _atomic_torch_save(state, ckpt_path)\n","\n","def load_bias_rl_checkpoint(ckpt_path, model, *, embedder, device=None, strict_embedder=True):\n","    d = dev(device)\n","    if not os.path.exists(ckpt_path):\n","        raise FileNotFoundError(ckpt_path)\n","    state = torch.load(ckpt_path, map_location=d, weights_only=False)\n","    _check_embedder_compat(embedder, state.get(\"embedder_sig\", {}), strict=strict_embedder)\n","    model.load_state_dict(state[\"model\"])\n","    return {\n","        \"bias_state\": state[\"bias_state\"],\n","        \"optimizer_state\": state.get(\"optimizer\"),\n","        \"episode\": int(state.get(\"episode\", 0)),\n","        \"smoothed_return\": state.get(\"smoothed_return\", None),\n","        \"best_metrics\": state.get(\"best_metrics\", {\"acc\": 0.0, \"multi_acc\": 0.0}),\n","        \"history\": _init_history(state.get(\"history\")),\n","        \"rng\": state.get(\"rng\", None),\n","    }"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ad5iLk-07Po6","executionInfo":{"status":"ok","timestamp":1761125601418,"user_tz":-180,"elapsed":7,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["def train_reinforce_random_prefix_with_bias(\n","    embedder: EmbeddedDatabase,\n","    mapper: SeqActMap,\n","    model: SequencePolicy,\n","    *,\n","    episodes: int = 16000,\n","    max_steps: int = 100,\n","    gamma: float = 0.99,\n","    lr: float = 3e-4,\n","    entropy_coef: float = 0.0,\n","    value_coef: float = 0.5,\n","    grad_clip: float = 1.0,\n","    r_correct: float = 1.0,\n","    r_wrong: float = -0.5,\n","    temperature: float = 1.0,\n","    bias: Optional[PrefixBiasTable] = None,\n","    bias_lr_pos: float = 0.5,\n","    bias_lr_neg: float = 0.5,\n","    bias_clip: float = 2.0,\n","    bias_scale: float = 1.0,\n","    use_backoff: Optional[int] = 5,\n","    batch_episodes: int = 100,\n","    eval_every: int = 2000,\n","    ckpt_path: Optional[str] = CKPT_PATH,\n","    ckpt_every: int = 2000,\n","    save_best_on_eval: bool = True,\n","    resume: bool = True,\n","    plot_every: Optional[int] = 2000,\n","    device: Optional[str] = None,\n","    seed: Optional[int] = 42,\n",") -> Tuple[torch.nn.Module, PrefixBiasTable]:\n","    if seed is not None:\n","        random.seed(seed); np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","    d = dev(device)\n","    model = model.to(d)\n","    model.train()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    V = embedder.V\n","    END_ID = embedder.end_id\n","    gt_pool, prefix2idx, prefix_list = build_prefix_pool_and_index(embedder)\n","    start_ep = 1\n","    smoothed_return: Optional[float] = None\n","    best_metrics = {\"acc\": 0.0, \"multi_acc\": 0.0}\n","    history = _init_history()\n","    if resume and ckpt_path and os.path.exists(ckpt_path):\n","        ck = load_bias_rl_checkpoint(ckpt_path, model, embedder=embedder, device=d)\n","        reindexed_state = _reindex_bias_rows_to_prefix_map(copy.deepcopy(ck[\"bias_state\"]), prefix2idx)\n","        bias = PrefixBiasTable.from_state(reindexed_state, device=d.type)\n","        optimizer.load_state_dict(ck[\"optimizer_state\"])\n","        start_ep = int(ck[\"episode\"]) + 1\n","        smoothed_return = ck[\"smoothed_return\"]\n","        best_metrics = ck.get(\"best_metrics\", best_metrics)\n","        history = ck.get(\"history\", history)\n","        if ck.get(\"rng\") is not None: _rng_unpak(ck[\"rng\"])\n","        print(f\"[Resume] {ckpt_path} -> start_ep={start_ep}, best={best_metrics}, \"\n","              f\"train_hist={len(history['train']['ep'])}, eval_hist={len(history['eval']['ep'])}\")\n","    else:\n","        if bias is None:\n","            bias = PrefixBiasTable(V=V, prefix2idx=prefix2idx, prefix_list=prefix_list, rows=None, device=d.type)\n","        else:\n","            rebased = _reindex_bias_rows_to_prefix_map(bias.state_dict(), prefix2idx)\n","            bias = PrefixBiasTable.from_state(rebased, device=d.type)\n","    batch_pol_t, batch_val_t, batch_ent_t = [], [], []\n","    temp = max(1e-6, float(temperature))\n","    final_ep = start_ep + episodes - 1\n","    out_dir = os.path.dirname(ckpt_path) if ckpt_path else \"/content\"\n","    try:\n","        for ep in range(start_ep, final_ep + 1):\n","            full_seq, i_start = gt_pool[np.random.randint(0, len(gt_pool))]\n","            state: List[int] = list(full_seq[:i_start])\n","            gt_i = int(i_start)\n","            rewards, dones, values = [], [], []\n","            states_t, lens_t, actions_t = [], [], []\n","            correct_steps = 0\n","            steps = 0\n","            while steps < max_steps:\n","                allowed = union_legals_from_map(mapper, state, max_backoff=use_backoff)\n","                if not allowed:\n","                    rewards.append(0.0); dones.append(True)\n","                    break\n","                mask = build_unbiased_union_mask(allowed, V, d.type)\n","                s_t = torch.tensor([state], dtype=torch.long, device=d)\n","                L_t = torch.tensor([len(state)], dtype=torch.long, device=d)\n","                logits, val = model(s_t, L_t, mask)\n","                b_row = bias.row_tensor(state, mask_float=mask, device=d)\n","                logits = logits + bias_scale * b_row\n","                probs = torch.softmax(logits / temp, dim=-1)\n","                action = int(torch.multinomial(probs, 1).item())\n","                target = full_seq[gt_i] if gt_i < len(full_seq) else END_ID\n","                is_correct = (action == target)\n","                reward = (r_correct if is_correct else r_wrong)\n","                done = (action == END_ID) and is_correct\n","                states_t.append(s_t.squeeze(0))\n","                lens_t.append(L_t.squeeze(0))\n","                actions_t.append(action)\n","                values.append(val.squeeze().item())\n","                rewards.append(float(reward))\n","                dones.append(bool(done))\n","                bias.update(state, action,\n","                            delta=(bias_lr_pos if reward > 0.0 else -bias_lr_neg),\n","                            clip=bias_clip)\n","                if is_correct:\n","                    correct_steps += 1\n","                    state.append(action)\n","                    if not done: gt_i += 1\n","                steps += 1\n","                if done: break\n","            last_value = 0.0\n","            if len(dones) and not dones[-1]:\n","                with torch.no_grad():\n","                    allowed = union_legals_from_map(mapper, state, max_backoff=use_backoff)\n","                    if allowed:\n","                        mask = build_unbiased_union_mask(allowed, V, d.type)\n","                        s_t = torch.tensor([state], dtype=torch.long, device=d)\n","                        L_t = torch.tensor([len(state)], dtype=torch.long, device=d)\n","                        last_value = float(model(s_t, L_t, mask)[1].squeeze().item())\n","            adv, ret = compute_gae(rewards, dones, values, gamma=gamma, lamd=1.0, last_value=last_value)\n","            adv_t = torch.tensor(adv, dtype=torch.float32, device=d)\n","            ret_t = torch.tensor(ret, dtype=torch.float32, device=d)\n","            if adv_t.numel() > 1:\n","                std = adv_t.std(unbiased=False)\n","                adv_t = (adv_t - adv_t.mean()) / (std + 1e-8) if torch.isfinite(std) and std > 0 else (adv_t - adv_t.mean())\n","            else:\n","                adv_t = torch.zeros_like(adv_t)\n","            step_pol, step_val, step_ent = [], [], []\n","            for i in range(len(actions_t)):\n","                a = torch.tensor([actions_t[i]], dtype=torch.long, device=d)\n","                s = states_t[i].unsqueeze(0).to(d)\n","                Ls = lens_t[i].unsqueeze(0).to(d)\n","                allowed_i = union_legals_from_map(mapper, s.squeeze(0).tolist(), max_backoff=use_backoff)\n","                mask_i = build_unbiased_union_mask(allowed_i, V, d.type)\n","                logits_i, v_i = model(s, Ls, mask_i)\n","                b_row_i = bias.row_tensor(s.squeeze(0).tolist(), mask_float=mask_i, device=d)\n","                logits_i = logits_i + bias_scale * b_row_i\n","                logp_all = torch.log_softmax(logits_i, dim=-1)\n","                p_all = logp_all.exp()\n","                logp = logp_all.gather(1, a.view(1,1)).squeeze()\n","                ent = -(p_all * logp_all).sum(dim=-1).squeeze()\n","                step_pol.append(-(logp * adv_t[i]))\n","                step_val.append(0.5 * (ret_t[i] - v_i.squeeze()).pow(2))\n","                step_ent.append(ent)\n","            if step_pol:\n","                ep_pol_t = torch.stack(step_pol).mean()\n","                ep_val_t = torch.stack(step_val).mean()\n","                ep_ent_t = torch.stack(step_ent).mean()\n","                batch_pol_t.append(ep_pol_t)\n","                batch_val_t.append(ep_val_t)\n","                batch_ent_t.append(ep_ent_t)\n","                ep_pol = float(ep_pol_t.detach().cpu())\n","                ep_val = float(ep_val_t.detach().cpu())\n","                ep_ent = float(ep_ent_t.detach().cpu())\n","            else:\n","                ep_pol_t = ep_val_t = ep_ent_t = None\n","                ep_pol = ep_val = ep_ent = float(\"nan\")\n","            ep_return = float(sum(rewards)) if rewards else 0.0\n","            smoothed_return = ep_return if smoothed_return is None else 0.95 * smoothed_return + 0.05 * ep_return\n","            corr_frac = (correct_steps / max(1, steps))\n","            history[\"train\"][\"ep\"].append(ep)\n","            history[\"train\"][\"return\"].append(ep_return)\n","            history[\"train\"][\"steps\"].append(steps)\n","            history[\"train\"][\"corr_frac\"].append(corr_frac)\n","            history[\"train\"][\"pol_loss\"].append(ep_pol)\n","            history[\"train\"][\"val_loss\"].append(ep_val)\n","            history[\"train\"][\"entropy\"].append(ep_ent)\n","            history[\"train\"][\"smooth_return\"].append(smoothed_return)\n","            W = 100\n","            avg_corr = _rolling_mean(history[\"train\"][\"corr_frac\"], W) * 100.0\n","            avg_Lp   = _rolling_mean(history[\"train\"][\"pol_loss\"], W)\n","            avg_Lv   = _rolling_mean(history[\"train\"][\"val_loss\"], W)\n","            avg_H    = _rolling_mean(history[\"train\"][\"entropy\"], W)\n","            print(\n","                f\"[Bias-RL] Ep {ep:6d} | steps={steps:3d} | \"\n","                f\"R={ep_return:+6.3f} (smooth {smoothed_return:+6.3f}) | \"\n","                f\"correct={corr_frac*100:5.1f}% | \"\n","                f\"Lp={ep_pol:.4f} Lv={ep_val:.4f} H={ep_ent:.3f} | \"\n","                f\"avg100: correct={avg_corr:5.1f}% Lp={avg_Lp:.4f} Lv={avg_Lv:.4f} H={avg_H:.3f}\"\n","            )\n","            if ep % batch_episodes == 0 and batch_pol_t:\n","                pol = torch.stack(batch_pol_t).mean()\n","                val = torch.stack(batch_val_t).mean()\n","                ent = torch.stack(batch_ent_t).mean()\n","                loss = pol + value_coef * val - entropy_coef * ent\n","                optimizer.zero_grad()\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","                optimizer.step()\n","                batch_pol_t.clear(); batch_val_t.clear(); batch_ent_t.clear()\n","            if eval_every and (ep % eval_every == 0):\n","                acc, macc = evaluate_with_bias(embedder, mapper, model, bias,\n","                                               max_backoff=use_backoff, show_progress=True, device=d.type)\n","                history[\"eval\"][\"ep\"].append(ep)\n","                history[\"eval\"][\"acc\"].append(float(acc))\n","                history[\"eval\"][\"multi_acc\"].append(float(macc))\n","\n","                if save_best_on_eval and ckpt_path:\n","                    if (macc > best_metrics.get(\"multi_acc\", 0.0)) or (acc > best_metrics.get(\"acc\", 0.0)):\n","                        best_metrics = {\"acc\": float(acc), \"multi_acc\": float(macc)}\n","                        best_path = ckpt_path.replace(\".pt\", \"_best.pt\")\n","                        save_bias_rl_checkpoint(best_path,\n","                                                model=model, optimizer=optimizer, bias=bias, embedder=embedder,\n","                                                ep=ep, smoothed_return=smoothed_return,\n","                                                best_metrics=best_metrics, history=history,\n","                                                rng_pack=_rng_pack(), tag=\"best\")\n","                        _save_history_artifacts(history, out_dir, tag=\"best\")\n","                        print(f\"[Checkpoint] BEST -> {best_path}  (acc={acc:.4f}, multi={macc:.4f})\")\n","            if ckpt_path and (ep % max(1, ckpt_every) == 0):\n","                save_bias_rl_checkpoint(ckpt_path,\n","                                        model=model, optimizer=optimizer, bias=bias, embedder=embedder,\n","                                        ep=ep, smoothed_return=smoothed_return,\n","                                        best_metrics=best_metrics, history=history,\n","                                        rng_pack=_rng_pack(), tag=\"latest\")\n","                _save_history_artifacts(history, out_dir, tag=\"latest\")\n","                if plot_every and (ep % plot_every == 0):\n","                    _save_history_artifacts(history, out_dir, tag=f\"ep{ep}\")\n","                print(f\"[Checkpoint] LATEST -> {ckpt_path}\")\n","        if ckpt_path:\n","            save_bias_rl_checkpoint(ckpt_path,\n","                                    model=model, optimizer=optimizer, bias=bias, embedder=embedder,\n","                                    ep=final_ep, smoothed_return=smoothed_return,\n","                                    best_metrics=best_metrics, history=history,\n","                                    rng_pack=_rng_pack(), tag=\"final\")\n","            _save_history_artifacts(history, out_dir, tag=\"final\")\n","            print(f\"[Checkpoint] FINAL -> {ckpt_path}\")\n","    except KeyboardInterrupt:\n","        if ckpt_path:\n","            ep_safe = max(start_ep, min(final_ep, ep))\n","            save_bias_rl_checkpoint(ckpt_path,\n","                                    model=model, optimizer=optimizer, bias=bias, embedder=embedder,\n","                                    ep=ep_safe, smoothed_return=smoothed_return,\n","                                    best_metrics=best_metrics, history=history,\n","                                    rng_pack=_rng_pack(), tag=\"interrupt\")\n","            _save_history_artifacts(history, out_dir, tag=\"interrupt\")\n","            print(f\"\\n[Checkpoint] INTERRUPT -> {ckpt_path}\")\n","        raise\n","\n","    return model, bias\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3I_FOjjzocaF","executionInfo":{"status":"ok","timestamp":1761125601464,"user_tz":-180,"elapsed":43,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":["if __name__ == \"__main__\":\n","    df = pd.read_csv(PATH)\n","    embedded = EmbeddedDatabase(df, min_len=2, remove_irr=True, remove_con=True)\n","    mapper = SeqActMap(embedded, min_len=1, max_len=28, min_seq_len=1)\n","    num_actions = embedded.V\n","    pad_id = embedded.pad_id\n","    model = SequencePolicy(action_size=num_actions, d_model=128, hidden=256, pad_id=pad_id)\n","    trained_model, bias = train_reinforce_random_prefix_with_bias(\n","        embedder=embedded,\n","        mapper=mapper,\n","        model=model,\n","        episodes=50000,\n","        max_steps=100,\n","        use_backoff=5,\n","        batch_episodes=100,\n","        eval_every=2000,\n","        ckpt_path=CKPT_PATH,\n","        ckpt_every=2000,\n","        save_best_on_eval=True,\n","        resume=True,\n","        seed=42\n","    )\n"]},{"cell_type":"code","source":["\n","OUT_CSV = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_project/RL/prefix_predictions.csv\"\n","MAX_PREFIXES = None\n","@torch.no_grad()\n","def export_prefix_predictions_min_csv(\n","    csv_path: str = OUT_CSV,\n","    dataset_csv: str = PATH,\n","    ckpt_path: str = CKPT_PATH,\n","    max_prefixes: int | None = MAX_PREFIXES,\n","    device: str | None = None,\n","):\n","    d = dev(device)\n","    df = pd.read_csv(dataset_csv)\n","    embedder = EmbeddedDatabase(df, min_len=2, remove_irr=True, remove_con=True)\n","    mapper = SeqActMap(embedder, min_len=1, max_len=28, min_seq_len=1)\n","    model = SequencePolicy(action_size=embedder.V, d_model=128, hidden=256, pad_id=embedder.pad_id).to(d)\n","    ck = load_bias_rl_checkpoint(ckpt_path, model, embedder=embedder, device=d, strict_embedder=True)\n","    _, prefix2idx_now, prefix_list_now = build_prefix_pool_and_index(embedder)\n","    bias_state = _reindex_bias_rows_to_prefix_map(copy.deepcopy(ck[\"bias_state\"]), prefix2idx_now)\n","    bias = PrefixBiasTable.from_state(bias_state, device=d.type)\n","    act_lookup = embedder.embed_to_act\n","    V = embedder.V\n","    model.eval()\n","    rows = []\n","    all_prefixes = list(bias.prefix_list)\n","    if max_prefixes is not None:\n","        all_prefixes = all_prefixes[:int(max_prefixes)]\n","\n","    try:\n","        from tqdm.auto import tqdm\n","        iterator = tqdm(all_prefixes, desc=\"[Export] Prefix→Prediction (min)\", leave=False)\n","    except Exception:\n","        iterator = all_prefixes\n","\n","    for pref in iterator:\n","        if pref is None:\n","            continue\n","        prefix_ids = list(pref)\n","        allowed = union_legals_from_map(mapper, prefix_ids, max_backoff=5)\n","        if not allowed:\n","            continue\n","        mask = build_unbiased_union_mask(allowed, V, d.type)\n","        s_t = torch.tensor([prefix_ids], dtype=torch.long, device=d)\n","        L_t = torch.tensor([len(prefix_ids)], dtype=torch.long, device=d)\n","\n","        logits, _ = model(s_t, L_t, mask)\n","        logits = logits + bias.row_tensor(prefix_ids, mask_float=mask, device=d)\n","        pred_id = int(torch.argmax(logits, dim=-1).item())\n","        prefix_text = \" | \".join(act_lookup[i] for i in prefix_ids)\n","        prediction_text = act_lookup[pred_id]\n","\n","        rows.append({\"prefix\": prefix_text, \"prediction\": prediction_text})\n","    out_df = pd.DataFrame(rows, columns=[\"prefix\", \"prediction\"])\n","    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n","    out_df.to_csv(csv_path, index=False)\n","    print(f\"[Export] Wrote {len(out_df)} rows to: {csv_path}\")\n","\n","export_prefix_predictions_min_csv()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35,"referenced_widgets":["84764179cdae4711a770c67bd1ae6271","db5cae5c1d394306a6d3a8b59946c1a2","df6efb8948594fc1acea6fc13aedf281","44d0e9bb480d47f197e6d830eeaaf6bd","e98d4fb3874e4e16892481e57d70e7f4","adb3937c169741aa95e68411f28c4471","626180cfe46c471e9307b99aebb32a55","54d0724a2acf43e6ab0daf48c7fbd0fd","959f989fabbc4516a7cd83c9aa6552f0","97499f0427834184914dbf4d91ad2207","4ee8fcc3e245409595b801db742739f6"]},"id":"YQ721_V8Sfuj","executionInfo":{"status":"ok","timestamp":1761126615192,"user_tz":-180,"elapsed":107168,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}},"outputId":"4cd68a23-dfd5-4fb2-982a-5936072277b5"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["[Export] Prefix→Prediction (min):   0%|          | 0/38407 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84764179cdae4711a770c67bd1ae6271"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[Export] Wrote 38407 rows to: /content/drive/MyDrive/Colab Notebooks/deep_learning_project/RL/prefix_predictions.csv\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HhgXfwKB7Q7m","executionInfo":{"status":"ok","timestamp":1761125718128,"user_tz":-180,"elapsed":56,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"6-2VLnnR7EhG","executionInfo":{"status":"ok","timestamp":1761125718131,"user_tz":-180,"elapsed":17,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"yqghi8mW7ocG","executionInfo":{"status":"ok","timestamp":1761125718133,"user_tz":-180,"elapsed":15,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"pHyxz01e7uCe","executionInfo":{"status":"ok","timestamp":1761125718135,"user_tz":-180,"elapsed":14,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"o-sRaID37yD2","executionInfo":{"status":"ok","timestamp":1761125718137,"user_tz":-180,"elapsed":13,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"vMICAJfnSI5B","executionInfo":{"status":"ok","timestamp":1761125718152,"user_tz":-180,"elapsed":5,"user":{"displayName":"David Roskin","userId":"03626795361254247188"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1kcQCNqhnD8yDQhFrwqbAymjrpnYFqKga","authorship_tag":"ABX9TyM0bN57RIBg4U8kEHuQkP79"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"84764179cdae4711a770c67bd1ae6271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db5cae5c1d394306a6d3a8b59946c1a2","IPY_MODEL_df6efb8948594fc1acea6fc13aedf281","IPY_MODEL_44d0e9bb480d47f197e6d830eeaaf6bd"],"layout":"IPY_MODEL_e98d4fb3874e4e16892481e57d70e7f4"}},"db5cae5c1d394306a6d3a8b59946c1a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adb3937c169741aa95e68411f28c4471","placeholder":"​","style":"IPY_MODEL_626180cfe46c471e9307b99aebb32a55","value":"[Export] Prefix→Prediction (min): 100%"}},"df6efb8948594fc1acea6fc13aedf281":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d0724a2acf43e6ab0daf48c7fbd0fd","max":38407,"min":0,"orientation":"horizontal","style":"IPY_MODEL_959f989fabbc4516a7cd83c9aa6552f0","value":38407}},"44d0e9bb480d47f197e6d830eeaaf6bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97499f0427834184914dbf4d91ad2207","placeholder":"​","style":"IPY_MODEL_4ee8fcc3e245409595b801db742739f6","value":" 38397/38407 [01:30&lt;00:00, 398.12it/s]"}},"e98d4fb3874e4e16892481e57d70e7f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"adb3937c169741aa95e68411f28c4471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"626180cfe46c471e9307b99aebb32a55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d0724a2acf43e6ab0daf48c7fbd0fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"959f989fabbc4516a7cd83c9aa6552f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97499f0427834184914dbf4d91ad2207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ee8fcc3e245409595b801db742739f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}